---
layout: post
title:  "Examination 1"
date:   2015-11-12 11:19:00
published: true
comments: true
categories: Examination 1
---

## Mina tankar kring pre-compiling CSS
Jag tycker att pre-compiling CSS i grunden är en bra utveckling av vanlig CSS. Trots att det kan öka komplexiteten i ett projekt så ser jag att fördelarna är mycket större än nackdelarna då upprepningen av kod kan minskas. Mindre upprepning av kod innebär även att risken för att småfel uppstår när kod ändras även den blir lägre.

Precis som vanlig CSS så kan pre-compiling CSS också delas upp i olika filer för att på så sätt få en bättre överblick över koden. Det som skiljer dessa två åt är dock att all pre-compiled CSS sammanställs till en vanlig CSS fil vilket är positivt för prestandan då endast en css-fil behöver hämtas. Pre-compiled CSS möjliggör även för minskad upprepning av kod. Detta sker genom att man kan definiera variabler och funktioner. Har man t.ex. en rubrik som man vill ska få ett specifikt utseende så kan man definiera detta utseende som en variabel. Andra rubriker kan sedan använda denna variabel för att ta del av samma regler samtidigt vissa av dessa regler kan skrivas över. Detta gör det även enklare att gör mindre förändringar av koden. Vill man t.ex. byta typsnitt så behöver man inte gå in och ändra varje värde som definierar en regel för typsnittet. Om värdena istället använder sig av en variabel som definierat en regel för typsnittet så behöver man endast byta typsnittet i den variabeln för att det ska påverka alla andra värden när en ny CSS-fil sammanställs. 

På min sida använder jag mig av en teknik som heter Sass (Stylistically Awesome Stylesheets). Mina Sass filer är i scss format, vilket är en förlängning av CSS3.

# För och nackdelar med pre-compiling CSS
Nackdelar med pre-compiled CSS är att man ökar komplexiteten i sitt projekt. Strukturerar man inte upp det på ett bra sätt så blir det lätt förvirrande (gäller i.o.f. även vanlig CSS) att hitta i koden. Även debuggandet försvåras eftersom flera filer sammanställs till en och därmed så får koden på en specifik rad i en pre-compiled CSS-fil en ny rad i den sammanställda CSS-filen. Detta problem går dock att lösa men precis som tidigare så blir detta mer komplext. Har man dock överseende med att komplexiteten ökar något så upplever jag att det finns mycket att vinna genom att använda sig pre-compiled CSS. Fördelarna är, precis som jag varit inne på tidigare, att man kan spara tid genom att minska upprepning av kod samtidigt som det går snabbare att ändra kod då en förändring inte nödvändigtvis innebär att man måste ändra på flera andra ställen i koden. 

# Mina tankar kring static site generators
Jag tycker att SSG:er är bra på många sätt. Ser man först och främst på den statiska sidan som de genererar så har den i sig mycket fördelar genom ökad säkerhet och högre prestanda än dynamiska sidor. SSG:er är även bra då de, precis som pre-compiling CSS, minskar upprepning av kod tack vare att man kan använda sig av ”templates”. SSG:en kan t.ex. generera fram en likadan footer till en webbplats alla sidor genom att man skrivit en template för detta. Därmed så behöver footerns kod endast skrivas en gång och man behöver då inte inkludera koden i webbplatsens alla html dokument. 

Jag upplever att det kan vara användbart att använda sig av SSG:er när man vill bygga en webbplats som är större än några få olika html dokument (förutsatt att det är en statisk sida som ska byggas). Är det ett väldigt litet projekt så kan det bli lite onödigt komplext och tiden man sparar på att använda SSG:er kan gå förlorat i det förberedande arbetet som en SSG kräver. Upplever man att sidan är så lite så att man har en bra översikt över vad som finns på de olika sidorna så kan SSG:en bli överflödig. Om ett projekt däremot är lite större så kan det vara lämpligt att använda sig av en SSG. Då kan man spara tid genom att mindre kod behöver upprepas och förändringar i koden behöver inte innebära att man måste ändra på flera andra ställen för att få en webbplats med ett enhetligt utseende

# robots.txt
robots.txt filer används för att ge instruktioner till web robotar som hoppar runt mellan olika websidor. Robotarnas syfte är olika men robots.txt ämnar dock till att ge alla och/eller specifika robotar instruktioner om vilka sidor på webbplatsen som dem har tillåtelse att besöka. Robotarna kan dock ignorera dessa instruktioner. En robots.txt är dock tillgänglig för alla så även vanliga användare kan gå in och titta på en webbplats robots.txt.
Jag har i min robots.txt valt att ge instruktioner till alla robotar och satt hela webbplatsen som ej tillgänglig. Jag har inget behov av att få min sida indexerad och vill helst inte att den skannas av om roboten är ute efter att samla in e-postadresser. Som tidigare nämnt så är dock detta ingen garanti för att roboten lyssnar på mina instruktioner.

# humans.txt
humans.txt filer är till för att användare av en webbplats ska kunna få reda på vem eller vilka som ligger bakom webbplatsen. Med humans.txt så försöker man att skapa en gemensam standard för detta så att alla användare vet var dem ska leta för att få fram rätt information istället för att man letar runt på olika ställen på olika webbplatser. 
Jag har i min humans.txt valt att skriva in mig själv som skapare och lägga till mitt Github namn, epost adress samt var jag kommer ifrån. Humans.txt förespråkar även att man skriver in lite info om webbplatsen. I min humans.txt så framgår när sidan senast uppdaterades, vilket språk den är skriven på, vilken doctype samt vilken IDE som använts när den utvecklats.

# Kommentarer
Jag använder mig av Disqus för att sköta hanteringen av kommentarer. Disqus tillhandahåller kod som implementerats på min webbplats. Koden ligger inom inläggets <article> tagg men har även en egen <section> och <article> tagg. Kommentarer kommer endast finnas tillgängligt på inlägg som har ”comments: true” i sin YAML Front Matter. 

# Open Graph
Open Graph är ett protokoll som ser till att det innehåll som visas när man försöker länka en sida är korrekt. Länkar man t.ex. en artikel från aftonbladet som har en tillhörande bild så vill man att den bilden visas i länken istället för exempelvis Aftonbladets logga. Med Open Graph är detta möjligt genom att sidornas olika grundläggande data kopplas till <meta> taggar i <head> delen. Den grundläggande data som Open Graph kräver är titel (titeln på det som länkas), type (vad för typ av objekt som länkas), image (vilken bild-url som det länkade objektet kan kopplas ihop med) och url (sidans url som kommer att kopplas ihop med länken och som man skickas till om man klickar på länken). Denna grundläggande data ses som egenskaper och det finns även fler egenskaper som man kan koppla till sina länkar för att öka chansen att länkarna visas på ett bättre och mer ändamålsenligt sätt. Jag har på min webbplats valt att endast använda de grundläggande egenskaperna eftersom min webbplats innehåll är väldigt basic då inläggen till största del består av en rubrik med tillhörande text. Bilder kan eventuellt finnas men om inte detta finns så är det meningen att image ska peka på en standard bild som representerar webbplatsen. Jag gjorde därför en enkel logga i Photoshop där jag inkluderade mitt namn. Den går att se nere till vänster i footern.

